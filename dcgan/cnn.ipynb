{"cells":[{"cell_type":"code","execution_count":119,"metadata":{},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torchvision\n","from torch.utils.data import DataLoader\n","from torchvision import transforms\n","\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","# device = torch.device(\"cpu\")\n"]},{"cell_type":"code","execution_count":120,"metadata":{},"outputs":[],"source":["# transform_train = transforms.Compose([transforms.ToTensor()])\n","transform_train = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.137,), (0.3081,))])\n","transform_valid = transforms.Compose([transforms.ToTensor()])\n","\n","trainset = torchvision.datasets.MNIST(root='./data', train=True,\n","                                      download=True, transform=transform_train)#, target_transform=lambda x: torch.Tensor([x]).float())\n","trainloader = DataLoader(trainset, batch_size=20,\n","                         shuffle=True, num_workers=0)\n","\n","testset = torchvision.datasets.MNIST(root='./data', train=False,\n","                                     download=True, transform=transform_valid) #target_transform=lambda x: torch.Tensor([x]).float())\n","testloader = DataLoader(testset, batch_size=20,\n","                        shuffle=False, num_workers=0)\n"]},{"cell_type":"code","execution_count":140,"metadata":{},"outputs":[],"source":["class Cnn(nn.Module):\n","    def __init__(self):\n","        super(Cnn, self).__init__()\n","        self.conv_blocks_1 = nn.Sequential(\n","            nn.Conv2d(1, 32, kernel_size=3, padding='same'),\n","            nn.ReLU(),\n","            nn.MaxPool2d(2, 2)\n","        )\n","        self.conv_blocks_2 = nn.Sequential(\n","            nn.Conv2d(32, 64, kernel_size=3, padding='same'),\n","            nn.ReLU(),\n","            nn.MaxPool2d(2, 2)\n","        )\n","        self.dropout = nn.Dropout(0.5)\n","        self.flatten = nn.Flatten(1)\n","        self.full_connection1 = nn.Sequential(\n","            nn.Linear(7 * 7 * 64, 1024),\n","            nn.ReLU()\n","        )\n","        self.out = nn.Linear(1024, 10)\n","\n","    def forward(self, x):\n","        x = self.conv_blocks_1(x)\n","        x = self.conv_blocks_2(x)\n","        x = self.flatten(x)\n","        x = self.full_connection1(x)\n","        x = self.dropout(x)\n","        x = self.out(x)\n","        return x\n","\n","\n","def metric_func(y_pred, y_true): return roc_auc_score(y_true=y_true.data.numpy(), y_score=y_pred.data.numpy())\n","\n","\n","matric_name = \"auc\"\n","\n","\n","def train_step(model: nn.Module, features: torch.Tensor, labels: torch.Tensor):\n","    features = features.to(device=device)\n","    labels = labels.to(device)\n","    optimizer.zero_grad()\n","    y_pred = model(features)\n","    loss = criterion(y_pred, labels)\n","    # metric = metric_func(y_pred, labels)\n","    metric = torch.Tensor(0)\n","    loss.backward()\n","    optimizer.step()\n","    return loss, 0\n"]},{"cell_type":"code","execution_count":141,"metadata":{},"outputs":[],"source":["from sklearn.metrics import roc_auc_score\n","\n","cnn = Cnn()\n","cnn.to(device)\n","criterion = nn.CrossEntropyLoss()\n","# criterion = nn.NLLLoss()\n","optimizer = torch.optim.SGD(cnn.parameters(), lr=0.1)"]},{"cell_type":"code","execution_count":142,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1           [-1, 32, 28, 28]             320\n","              ReLU-2           [-1, 32, 28, 28]               0\n","         MaxPool2d-3           [-1, 32, 14, 14]               0\n","            Conv2d-4           [-1, 64, 14, 14]          18,496\n","              ReLU-5           [-1, 64, 14, 14]               0\n","         MaxPool2d-6             [-1, 64, 7, 7]               0\n","           Flatten-7                 [-1, 3136]               0\n","            Linear-8                 [-1, 1024]       3,212,288\n","              ReLU-9                 [-1, 1024]               0\n","          Dropout-10                 [-1, 1024]               0\n","           Linear-11                   [-1, 10]          10,250\n","================================================================\n","Total params: 3,241,354\n","Trainable params: 3,241,354\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.002991\n","Forward/backward pass size (MB): 0.693436\n","Params size (MB): 12.364784\n","Estimated Total Size (MB): 13.061211\n","----------------------------------------------------------------\n"]}],"source":["import torchkeras\n","input_shape = (1, 28, 28)\n","torchkeras.summary(Cnn(), input_shape=(1, 28, 28))"]},{"cell_type":"code","execution_count":143,"metadata":{},"outputs":[],"source":["from torch.utils.tensorboard import SummaryWriter\n","writer = SummaryWriter('./graph/tensorboard')\n","writer.add_graph(Cnn(),input_to_model = torch.rand(100, 1,28,28))\n","writer.close()"]},{"cell_type":"code","execution_count":124,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["<torch.utils.data.sampler.BatchSampler object at 0x000002997D4F6A48>\n","3000\n"]}],"source":["(features, labels) = next(iter(trainloader))\n","# print((features[0], labels[0]))\n","print(trainloader.batch_sampler)\n","print(len(trainloader))"]},{"cell_type":"code","execution_count":125,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[epoch: 1, id:     1,   0%] loss: 2.310\n","[epoch: 1, id:   101,   3%] loss: 1.028\n","[epoch: 1, id:   201,   6%] loss: 0.681\n","[epoch: 1, id:   301,  10%] loss: 0.527\n","[epoch: 1, id:   401,  13%] loss: 0.441\n","[epoch: 1, id:   501,  16%] loss: 0.382\n","[epoch: 1, id:   601,  20%] loss: 0.346\n","[epoch: 1, id:   701,  23%] loss: 0.317\n","[epoch: 1, id:   801,  26%] loss: 0.294\n","[epoch: 1, id:   901,  30%] loss: 0.275\n","[epoch: 1, id:  1001,  33%] loss: 0.258\n","[epoch: 1, id:  1101,  36%] loss: 0.243\n","[epoch: 1, id:  1201,  40%] loss: 0.232\n","[epoch: 1, id:  1301,  43%] loss: 0.220\n","[epoch: 1, id:  1401,  46%] loss: 0.210\n","[epoch: 1, id:  1501,  50%] loss: 0.204\n","[epoch: 1, id:  1601,  53%] loss: 0.196\n","[epoch: 1, id:  1701,  56%] loss: 0.190\n","[epoch: 1, id:  1801,  60%] loss: 0.183\n","[epoch: 1, id:  1901,  63%] loss: 0.178\n","[epoch: 1, id:  2001,  66%] loss: 0.173\n","[epoch: 1, id:  2101,  70%] loss: 0.169\n","[epoch: 1, id:  2201,  73%] loss: 0.165\n","[epoch: 1, id:  2301,  76%] loss: 0.162\n","[epoch: 1, id:  2401,  80%] loss: 0.158\n","[epoch: 1, id:  2501,  83%] loss: 0.155\n","[epoch: 1, id:  2601,  86%] loss: 0.152\n","[epoch: 1, id:  2701,  90%] loss: 0.148\n","[epoch: 1, id:  2801,  93%] loss: 0.146\n","[epoch: 1, id:  2901,  96%] loss: 0.143\n","[epoch: 2, id:     1,   0%] loss: 0.121\n","[epoch: 2, id:   101,   3%] loss: 0.050\n","[epoch: 2, id:   201,   6%] loss: 0.064\n","[epoch: 2, id:   301,  10%] loss: 0.058\n","[epoch: 2, id:   401,  13%] loss: 0.061\n","[epoch: 2, id:   501,  16%] loss: 0.061\n","[epoch: 2, id:   601,  20%] loss: 0.061\n","[epoch: 2, id:   701,  23%] loss: 0.058\n","[epoch: 2, id:   801,  26%] loss: 0.058\n","[epoch: 2, id:   901,  30%] loss: 0.057\n","[epoch: 2, id:  1001,  33%] loss: 0.057\n","[epoch: 2, id:  1101,  36%] loss: 0.057\n","[epoch: 2, id:  1201,  40%] loss: 0.056\n","[epoch: 2, id:  1301,  43%] loss: 0.058\n","[epoch: 2, id:  1401,  46%] loss: 0.058\n","[epoch: 2, id:  1501,  50%] loss: 0.058\n","[epoch: 2, id:  1601,  53%] loss: 0.058\n","[epoch: 2, id:  1701,  56%] loss: 0.057\n","[epoch: 2, id:  1801,  60%] loss: 0.057\n","[epoch: 2, id:  1901,  63%] loss: 0.057\n","[epoch: 2, id:  2001,  66%] loss: 0.056\n","[epoch: 2, id:  2101,  70%] loss: 0.056\n","[epoch: 2, id:  2201,  73%] loss: 0.056\n","[epoch: 2, id:  2301,  76%] loss: 0.055\n","[epoch: 2, id:  2401,  80%] loss: 0.054\n","[epoch: 2, id:  2501,  83%] loss: 0.054\n","[epoch: 2, id:  2601,  86%] loss: 0.053\n","[epoch: 2, id:  2701,  90%] loss: 0.053\n","[epoch: 2, id:  2801,  93%] loss: 0.052\n","[epoch: 2, id:  2901,  96%] loss: 0.052\n","[epoch: 3, id:     1,   0%] loss: 0.001\n","[epoch: 3, id:   101,   3%] loss: 0.037\n","[epoch: 3, id:   201,   6%] loss: 0.036\n","[epoch: 3, id:   301,  10%] loss: 0.033\n","[epoch: 3, id:   401,  13%] loss: 0.032\n","[epoch: 3, id:   501,  16%] loss: 0.033\n","[epoch: 3, id:   601,  20%] loss: 0.031\n","[epoch: 3, id:   701,  23%] loss: 0.033\n","[epoch: 3, id:   801,  26%] loss: 0.033\n","[epoch: 3, id:   901,  30%] loss: 0.033\n","[epoch: 3, id:  1001,  33%] loss: 0.034\n","[epoch: 3, id:  1101,  36%] loss: 0.034\n","[epoch: 3, id:  1201,  40%] loss: 0.034\n","[epoch: 3, id:  1301,  43%] loss: 0.033\n","[epoch: 3, id:  1401,  46%] loss: 0.033\n","[epoch: 3, id:  1501,  50%] loss: 0.034\n","[epoch: 3, id:  1601,  53%] loss: 0.034\n","[epoch: 3, id:  1701,  56%] loss: 0.034\n","[epoch: 3, id:  1801,  60%] loss: 0.035\n","[epoch: 3, id:  1901,  63%] loss: 0.036\n","[epoch: 3, id:  2001,  66%] loss: 0.035\n","[epoch: 3, id:  2101,  70%] loss: 0.036\n","[epoch: 3, id:  2201,  73%] loss: 0.035\n","[epoch: 3, id:  2301,  76%] loss: 0.035\n","[epoch: 3, id:  2401,  80%] loss: 0.036\n","[epoch: 3, id:  2501,  83%] loss: 0.036\n","[epoch: 3, id:  2601,  86%] loss: 0.036\n","[epoch: 3, id:  2701,  90%] loss: 0.036\n","[epoch: 3, id:  2801,  93%] loss: 0.036\n","[epoch: 3, id:  2901,  96%] loss: 0.036\n","[epoch: 4, id:     1,   0%] loss: 0.002\n","[epoch: 4, id:   101,   3%] loss: 0.029\n","[epoch: 4, id:   201,   6%] loss: 0.026\n","[epoch: 4, id:   301,  10%] loss: 0.024\n","[epoch: 4, id:   401,  13%] loss: 0.026\n","[epoch: 4, id:   501,  16%] loss: 0.029\n","[epoch: 4, id:   601,  20%] loss: 0.029\n","[epoch: 4, id:   701,  23%] loss: 0.028\n","[epoch: 4, id:   801,  26%] loss: 0.028\n","[epoch: 4, id:   901,  30%] loss: 0.028\n","[epoch: 4, id:  1001,  33%] loss: 0.027\n","[epoch: 4, id:  1101,  36%] loss: 0.026\n","[epoch: 4, id:  1201,  40%] loss: 0.027\n","[epoch: 4, id:  1301,  43%] loss: 0.028\n","[epoch: 4, id:  1401,  46%] loss: 0.028\n","[epoch: 4, id:  1501,  50%] loss: 0.028\n","[epoch: 4, id:  1601,  53%] loss: 0.027\n","[epoch: 4, id:  1701,  56%] loss: 0.027\n","[epoch: 4, id:  1801,  60%] loss: 0.026\n","[epoch: 4, id:  1901,  63%] loss: 0.026\n","[epoch: 4, id:  2001,  66%] loss: 0.026\n","[epoch: 4, id:  2101,  70%] loss: 0.026\n","[epoch: 4, id:  2201,  73%] loss: 0.026\n","[epoch: 4, id:  2301,  76%] loss: 0.026\n","[epoch: 4, id:  2401,  80%] loss: 0.025\n","[epoch: 4, id:  2501,  83%] loss: 0.025\n","[epoch: 4, id:  2601,  86%] loss: 0.025\n","[epoch: 4, id:  2701,  90%] loss: 0.025\n","[epoch: 4, id:  2801,  93%] loss: 0.025\n","[epoch: 4, id:  2901,  96%] loss: 0.025\n","[epoch: 5, id:     1,   0%] loss: 0.009\n","[epoch: 5, id:   101,   3%] loss: 0.014\n","[epoch: 5, id:   201,   6%] loss: 0.022\n","[epoch: 5, id:   301,  10%] loss: 0.021\n","[epoch: 5, id:   401,  13%] loss: 0.021\n","[epoch: 5, id:   501,  16%] loss: 0.020\n","[epoch: 5, id:   601,  20%] loss: 0.020\n","[epoch: 5, id:   701,  23%] loss: 0.021\n","[epoch: 5, id:   801,  26%] loss: 0.020\n","[epoch: 5, id:   901,  30%] loss: 0.020\n","[epoch: 5, id:  1001,  33%] loss: 0.020\n","[epoch: 5, id:  1101,  36%] loss: 0.020\n","[epoch: 5, id:  1201,  40%] loss: 0.021\n","[epoch: 5, id:  1301,  43%] loss: 0.020\n","[epoch: 5, id:  1401,  46%] loss: 0.020\n","[epoch: 5, id:  1501,  50%] loss: 0.021\n","[epoch: 5, id:  1601,  53%] loss: 0.021\n","[epoch: 5, id:  1701,  56%] loss: 0.021\n","[epoch: 5, id:  1801,  60%] loss: 0.022\n","[epoch: 5, id:  1901,  63%] loss: 0.022\n","[epoch: 5, id:  2001,  66%] loss: 0.021\n","[epoch: 5, id:  2101,  70%] loss: 0.021\n","[epoch: 5, id:  2201,  73%] loss: 0.021\n","[epoch: 5, id:  2301,  76%] loss: 0.021\n","[epoch: 5, id:  2401,  80%] loss: 0.021\n","[epoch: 5, id:  2501,  83%] loss: 0.021\n","[epoch: 5, id:  2601,  86%] loss: 0.021\n","[epoch: 5, id:  2701,  90%] loss: 0.021\n","[epoch: 5, id:  2801,  93%] loss: 0.021\n","[epoch: 5, id:  2901,  96%] loss: 0.021\n","[epoch: 6, id:     1,   0%] loss: 0.023\n","[epoch: 6, id:   101,   3%] loss: 0.017\n","[epoch: 6, id:   201,   6%] loss: 0.016\n","[epoch: 6, id:   301,  10%] loss: 0.014\n","[epoch: 6, id:   401,  13%] loss: 0.013\n","[epoch: 6, id:   501,  16%] loss: 0.013\n","[epoch: 6, id:   601,  20%] loss: 0.013\n","[epoch: 6, id:   701,  23%] loss: 0.013\n","[epoch: 6, id:   801,  26%] loss: 0.014\n","[epoch: 6, id:   901,  30%] loss: 0.014\n","[epoch: 6, id:  1001,  33%] loss: 0.014\n","[epoch: 6, id:  1101,  36%] loss: 0.014\n","[epoch: 6, id:  1201,  40%] loss: 0.015\n","[epoch: 6, id:  1301,  43%] loss: 0.015\n","[epoch: 6, id:  1401,  46%] loss: 0.016\n","[epoch: 6, id:  1501,  50%] loss: 0.016\n","[epoch: 6, id:  1601,  53%] loss: 0.016\n","[epoch: 6, id:  1701,  56%] loss: 0.016\n","[epoch: 6, id:  1801,  60%] loss: 0.016\n","[epoch: 6, id:  1901,  63%] loss: 0.016\n","[epoch: 6, id:  2001,  66%] loss: 0.016\n","[epoch: 6, id:  2101,  70%] loss: 0.015\n","[epoch: 6, id:  2201,  73%] loss: 0.015\n","[epoch: 6, id:  2301,  76%] loss: 0.015\n","[epoch: 6, id:  2401,  80%] loss: 0.016\n","[epoch: 6, id:  2501,  83%] loss: 0.016\n","[epoch: 6, id:  2601,  86%] loss: 0.016\n","[epoch: 6, id:  2701,  90%] loss: 0.016\n","[epoch: 6, id:  2801,  93%] loss: 0.016\n","[epoch: 6, id:  2901,  96%] loss: 0.016\n","[epoch: 7, id:     1,   0%] loss: 0.003\n","[epoch: 7, id:   101,   3%] loss: 0.010\n","[epoch: 7, id:   201,   6%] loss: 0.009\n","[epoch: 7, id:   301,  10%] loss: 0.008\n","[epoch: 7, id:   401,  13%] loss: 0.007\n","[epoch: 7, id:   501,  16%] loss: 0.009\n","[epoch: 7, id:   601,  20%] loss: 0.010\n","[epoch: 7, id:   701,  23%] loss: 0.012\n","[epoch: 7, id:   801,  26%] loss: 0.012\n","[epoch: 7, id:   901,  30%] loss: 0.013\n","[epoch: 7, id:  1001,  33%] loss: 0.013\n","[epoch: 7, id:  1101,  36%] loss: 0.013\n","[epoch: 7, id:  1201,  40%] loss: 0.014\n","[epoch: 7, id:  1301,  43%] loss: 0.014\n","[epoch: 7, id:  1401,  46%] loss: 0.014\n","[epoch: 7, id:  1501,  50%] loss: 0.014\n","[epoch: 7, id:  1601,  53%] loss: 0.014\n","[epoch: 7, id:  1701,  56%] loss: 0.014\n","[epoch: 7, id:  1801,  60%] loss: 0.015\n","[epoch: 7, id:  1901,  63%] loss: 0.014\n","[epoch: 7, id:  2001,  66%] loss: 0.014\n","[epoch: 7, id:  2101,  70%] loss: 0.014\n","[epoch: 7, id:  2201,  73%] loss: 0.015\n","[epoch: 7, id:  2301,  76%] loss: 0.015\n","[epoch: 7, id:  2401,  80%] loss: 0.015\n","[epoch: 7, id:  2501,  83%] loss: 0.015\n","[epoch: 7, id:  2601,  86%] loss: 0.015\n","[epoch: 7, id:  2701,  90%] loss: 0.015\n","[epoch: 7, id:  2801,  93%] loss: 0.015\n","[epoch: 7, id:  2901,  96%] loss: 0.015\n","[epoch: 8, id:     1,   0%] loss: 0.000\n","[epoch: 8, id:   101,   3%] loss: 0.017\n","[epoch: 8, id:   201,   6%] loss: 0.012\n","[epoch: 8, id:   301,  10%] loss: 0.011\n","[epoch: 8, id:   401,  13%] loss: 0.012\n","[epoch: 8, id:   501,  16%] loss: 0.011\n","[epoch: 8, id:   601,  20%] loss: 0.012\n","[epoch: 8, id:   701,  23%] loss: 0.012\n","[epoch: 8, id:   801,  26%] loss: 0.012\n","[epoch: 8, id:   901,  30%] loss: 0.012\n","[epoch: 8, id:  1001,  33%] loss: 0.012\n","[epoch: 8, id:  1101,  36%] loss: 0.012\n","[epoch: 8, id:  1201,  40%] loss: 0.012\n","[epoch: 8, id:  1301,  43%] loss: 0.012\n","[epoch: 8, id:  1401,  46%] loss: 0.013\n","[epoch: 8, id:  1501,  50%] loss: 0.013\n","[epoch: 8, id:  1601,  53%] loss: 0.013\n","[epoch: 8, id:  1701,  56%] loss: 0.012\n","[epoch: 8, id:  1801,  60%] loss: 0.012\n","[epoch: 8, id:  1901,  63%] loss: 0.012\n","[epoch: 8, id:  2001,  66%] loss: 0.012\n","[epoch: 8, id:  2101,  70%] loss: 0.012\n","[epoch: 8, id:  2201,  73%] loss: 0.013\n","[epoch: 8, id:  2301,  76%] loss: 0.013\n","[epoch: 8, id:  2401,  80%] loss: 0.013\n","[epoch: 8, id:  2501,  83%] loss: 0.013\n","[epoch: 8, id:  2601,  86%] loss: 0.013\n","[epoch: 8, id:  2701,  90%] loss: 0.013\n","[epoch: 8, id:  2801,  93%] loss: 0.013\n","[epoch: 8, id:  2901,  96%] loss: 0.013\n","[epoch: 9, id:     1,   0%] loss: 0.009\n","[epoch: 9, id:   101,   3%] loss: 0.008\n","[epoch: 9, id:   201,   6%] loss: 0.007\n","[epoch: 9, id:   301,  10%] loss: 0.007\n","[epoch: 9, id:   401,  13%] loss: 0.007\n","[epoch: 9, id:   501,  16%] loss: 0.006\n","[epoch: 9, id:   601,  20%] loss: 0.007\n","[epoch: 9, id:   701,  23%] loss: 0.008\n","[epoch: 9, id:   801,  26%] loss: 0.008\n","[epoch: 9, id:   901,  30%] loss: 0.008\n","[epoch: 9, id:  1001,  33%] loss: 0.008\n","[epoch: 9, id:  1101,  36%] loss: 0.007\n","[epoch: 9, id:  1201,  40%] loss: 0.007\n","[epoch: 9, id:  1301,  43%] loss: 0.007\n","[epoch: 9, id:  1401,  46%] loss: 0.008\n","[epoch: 9, id:  1501,  50%] loss: 0.008\n","[epoch: 9, id:  1601,  53%] loss: 0.008\n","[epoch: 9, id:  1701,  56%] loss: 0.008\n","[epoch: 9, id:  1801,  60%] loss: 0.008\n","[epoch: 9, id:  1901,  63%] loss: 0.008\n","[epoch: 9, id:  2001,  66%] loss: 0.009\n","[epoch: 9, id:  2101,  70%] loss: 0.009\n","[epoch: 9, id:  2201,  73%] loss: 0.009\n","[epoch: 9, id:  2301,  76%] loss: 0.009\n","[epoch: 9, id:  2401,  80%] loss: 0.009\n","[epoch: 9, id:  2501,  83%] loss: 0.009\n","[epoch: 9, id:  2601,  86%] loss: 0.010\n","[epoch: 9, id:  2701,  90%] loss: 0.009\n","[epoch: 9, id:  2801,  93%] loss: 0.010\n","[epoch: 9, id:  2901,  96%] loss: 0.010\n","[epoch: 10, id:     1,   0%] loss: 0.000\n","[epoch: 10, id:   101,   3%] loss: 0.005\n","[epoch: 10, id:   201,   6%] loss: 0.007\n","[epoch: 10, id:   301,  10%] loss: 0.008\n","[epoch: 10, id:   401,  13%] loss: 0.007\n","[epoch: 10, id:   501,  16%] loss: 0.007\n","[epoch: 10, id:   601,  20%] loss: 0.006\n","[epoch: 10, id:   701,  23%] loss: 0.006\n","[epoch: 10, id:   801,  26%] loss: 0.007\n","[epoch: 10, id:   901,  30%] loss: 0.008\n","[epoch: 10, id:  1001,  33%] loss: 0.008\n","[epoch: 10, id:  1101,  36%] loss: 0.008\n","[epoch: 10, id:  1201,  40%] loss: 0.008\n","[epoch: 10, id:  1301,  43%] loss: 0.008\n","[epoch: 10, id:  1401,  46%] loss: 0.009\n","[epoch: 10, id:  1501,  50%] loss: 0.009\n","[epoch: 10, id:  1601,  53%] loss: 0.009\n","[epoch: 10, id:  1701,  56%] loss: 0.010\n","[epoch: 10, id:  1801,  60%] loss: 0.010\n","[epoch: 10, id:  1901,  63%] loss: 0.010\n","[epoch: 10, id:  2001,  66%] loss: 0.010\n","[epoch: 10, id:  2101,  70%] loss: 0.010\n","[epoch: 10, id:  2201,  73%] loss: 0.010\n","[epoch: 10, id:  2301,  76%] loss: 0.010\n","[epoch: 10, id:  2401,  80%] loss: 0.010\n","[epoch: 10, id:  2501,  83%] loss: 0.010\n","[epoch: 10, id:  2601,  86%] loss: 0.010\n","[epoch: 10, id:  2701,  90%] loss: 0.010\n","[epoch: 10, id:  2801,  93%] loss: 0.010\n","[epoch: 10, id:  2901,  96%] loss: 0.010\n","[epoch: 11, id:     1,   0%] loss: 0.000\n","[epoch: 11, id:   101,   3%] loss: 0.005\n","[epoch: 11, id:   201,   6%] loss: 0.008\n","[epoch: 11, id:   301,  10%] loss: 0.008\n","[epoch: 11, id:   401,  13%] loss: 0.006\n","[epoch: 11, id:   501,  16%] loss: 0.006\n","[epoch: 11, id:   601,  20%] loss: 0.006\n","[epoch: 11, id:   701,  23%] loss: 0.006\n","[epoch: 11, id:   801,  26%] loss: 0.006\n","[epoch: 11, id:   901,  30%] loss: 0.006\n","[epoch: 11, id:  1001,  33%] loss: 0.007\n","[epoch: 11, id:  1101,  36%] loss: 0.007\n","[epoch: 11, id:  1201,  40%] loss: 0.007\n","[epoch: 11, id:  1301,  43%] loss: 0.006\n","[epoch: 11, id:  1401,  46%] loss: 0.007\n","[epoch: 11, id:  1501,  50%] loss: 0.007\n","[epoch: 11, id:  1601,  53%] loss: 0.007\n","[epoch: 11, id:  1701,  56%] loss: 0.007\n","[epoch: 11, id:  1801,  60%] loss: 0.006\n","[epoch: 11, id:  1901,  63%] loss: 0.007\n","[epoch: 11, id:  2001,  66%] loss: 0.007\n","[epoch: 11, id:  2101,  70%] loss: 0.007\n","[epoch: 11, id:  2201,  73%] loss: 0.007\n","[epoch: 11, id:  2301,  76%] loss: 0.007\n","[epoch: 11, id:  2401,  80%] loss: 0.007\n","[epoch: 11, id:  2501,  83%] loss: 0.007\n","[epoch: 11, id:  2601,  86%] loss: 0.007\n","[epoch: 11, id:  2701,  90%] loss: 0.008\n","[epoch: 11, id:  2801,  93%] loss: 0.008\n","[epoch: 11, id:  2901,  96%] loss: 0.008\n","[epoch: 12, id:     1,   0%] loss: 0.000\n","[epoch: 12, id:   101,   3%] loss: 0.009\n","[epoch: 12, id:   201,   6%] loss: 0.010\n","[epoch: 12, id:   301,  10%] loss: 0.009\n","[epoch: 12, id:   401,  13%] loss: 0.009\n","[epoch: 12, id:   501,  16%] loss: 0.011\n","[epoch: 12, id:   601,  20%] loss: 0.011\n","[epoch: 12, id:   701,  23%] loss: 0.011\n","[epoch: 12, id:   801,  26%] loss: 0.011\n","[epoch: 12, id:   901,  30%] loss: 0.010\n","[epoch: 12, id:  1001,  33%] loss: 0.010\n","[epoch: 12, id:  1101,  36%] loss: 0.009\n","[epoch: 12, id:  1201,  40%] loss: 0.009\n","[epoch: 12, id:  1301,  43%] loss: 0.009\n","[epoch: 12, id:  1401,  46%] loss: 0.009\n","[epoch: 12, id:  1501,  50%] loss: 0.010\n","[epoch: 12, id:  1601,  53%] loss: 0.009\n","[epoch: 12, id:  1701,  56%] loss: 0.009\n","[epoch: 12, id:  1801,  60%] loss: 0.009\n","[epoch: 12, id:  1901,  63%] loss: 0.009\n","[epoch: 12, id:  2001,  66%] loss: 0.009\n","[epoch: 12, id:  2101,  70%] loss: 0.009\n","[epoch: 12, id:  2201,  73%] loss: 0.009\n","[epoch: 12, id:  2301,  76%] loss: 0.008\n","[epoch: 12, id:  2401,  80%] loss: 0.009\n","[epoch: 12, id:  2501,  83%] loss: 0.009\n","[epoch: 12, id:  2601,  86%] loss: 0.008\n","[epoch: 12, id:  2701,  90%] loss: 0.009\n","[epoch: 12, id:  2801,  93%] loss: 0.009\n","[epoch: 12, id:  2901,  96%] loss: 0.009\n","[epoch: 13, id:     1,   0%] loss: 0.155\n","[epoch: 13, id:   101,   3%] loss: 0.009\n","[epoch: 13, id:   201,   6%] loss: 0.009\n","[epoch: 13, id:   301,  10%] loss: 0.008\n","[epoch: 13, id:   401,  13%] loss: 0.007\n","[epoch: 13, id:   501,  16%] loss: 0.006\n","[epoch: 13, id:   601,  20%] loss: 0.005\n","[epoch: 13, id:   701,  23%] loss: 0.006\n","[epoch: 13, id:   801,  26%] loss: 0.007\n","[epoch: 13, id:   901,  30%] loss: 0.006\n","[epoch: 13, id:  1001,  33%] loss: 0.006\n","[epoch: 13, id:  1101,  36%] loss: 0.006\n","[epoch: 13, id:  1201,  40%] loss: 0.006\n","[epoch: 13, id:  1301,  43%] loss: 0.006\n","[epoch: 13, id:  1401,  46%] loss: 0.006\n","[epoch: 13, id:  1501,  50%] loss: 0.006\n","[epoch: 13, id:  1601,  53%] loss: 0.006\n","[epoch: 13, id:  1701,  56%] loss: 0.006\n","[epoch: 13, id:  1801,  60%] loss: 0.006\n","[epoch: 13, id:  1901,  63%] loss: 0.006\n","[epoch: 13, id:  2001,  66%] loss: 0.006\n","[epoch: 13, id:  2101,  70%] loss: 0.006\n","[epoch: 13, id:  2201,  73%] loss: 0.007\n","[epoch: 13, id:  2301,  76%] loss: 0.007\n","[epoch: 13, id:  2401,  80%] loss: 0.007\n","[epoch: 13, id:  2501,  83%] loss: 0.007\n","[epoch: 13, id:  2601,  86%] loss: 0.007\n","[epoch: 13, id:  2701,  90%] loss: 0.007\n","[epoch: 13, id:  2801,  93%] loss: 0.007\n","[epoch: 13, id:  2901,  96%] loss: 0.007\n","[epoch: 14, id:     1,   0%] loss: 0.000\n","[epoch: 14, id:   101,   3%] loss: 0.009\n","[epoch: 14, id:   201,   6%] loss: 0.006\n","[epoch: 14, id:   301,  10%] loss: 0.005\n","[epoch: 14, id:   401,  13%] loss: 0.005\n","[epoch: 14, id:   501,  16%] loss: 0.005\n","[epoch: 14, id:   601,  20%] loss: 0.004\n","[epoch: 14, id:   701,  23%] loss: 0.005\n","[epoch: 14, id:   801,  26%] loss: 0.005\n","[epoch: 14, id:   901,  30%] loss: 0.005\n","[epoch: 14, id:  1001,  33%] loss: 0.006\n","[epoch: 14, id:  1101,  36%] loss: 0.005\n","[epoch: 14, id:  1201,  40%] loss: 0.006\n","[epoch: 14, id:  1301,  43%] loss: 0.007\n","[epoch: 14, id:  1401,  46%] loss: 0.007\n","[epoch: 14, id:  1501,  50%] loss: 0.007\n","[epoch: 14, id:  1601,  53%] loss: 0.007\n","[epoch: 14, id:  1701,  56%] loss: 0.008\n","[epoch: 14, id:  1801,  60%] loss: 0.007\n","[epoch: 14, id:  1901,  63%] loss: 0.007\n","[epoch: 14, id:  2001,  66%] loss: 0.007\n","[epoch: 14, id:  2101,  70%] loss: 0.007\n","[epoch: 14, id:  2201,  73%] loss: 0.007\n","[epoch: 14, id:  2301,  76%] loss: 0.007\n","[epoch: 14, id:  2401,  80%] loss: 0.007\n","[epoch: 14, id:  2501,  83%] loss: 0.008\n","[epoch: 14, id:  2601,  86%] loss: 0.008\n","[epoch: 14, id:  2701,  90%] loss: 0.008\n","[epoch: 14, id:  2801,  93%] loss: 0.008\n","[epoch: 14, id:  2901,  96%] loss: 0.008\n","[epoch: 15, id:     1,   0%] loss: 0.014\n","[epoch: 15, id:   101,   3%] loss: 0.009\n","[epoch: 15, id:   201,   6%] loss: 0.007\n","[epoch: 15, id:   301,  10%] loss: 0.010\n","[epoch: 15, id:   401,  13%] loss: 0.009\n","[epoch: 15, id:   501,  16%] loss: 0.009\n","[epoch: 15, id:   601,  20%] loss: 0.008\n","[epoch: 15, id:   701,  23%] loss: 0.008\n","[epoch: 15, id:   801,  26%] loss: 0.008\n","[epoch: 15, id:   901,  30%] loss: 0.007\n","[epoch: 15, id:  1001,  33%] loss: 0.007\n","[epoch: 15, id:  1101,  36%] loss: 0.007\n","[epoch: 15, id:  1201,  40%] loss: 0.007\n","[epoch: 15, id:  1301,  43%] loss: 0.007\n","[epoch: 15, id:  1401,  46%] loss: 0.006\n","[epoch: 15, id:  1501,  50%] loss: 0.006\n","[epoch: 15, id:  1601,  53%] loss: 0.006\n","[epoch: 15, id:  1701,  56%] loss: 0.006\n","[epoch: 15, id:  1801,  60%] loss: 0.006\n","[epoch: 15, id:  1901,  63%] loss: 0.006\n","[epoch: 15, id:  2001,  66%] loss: 0.006\n","[epoch: 15, id:  2101,  70%] loss: 0.007\n","[epoch: 15, id:  2201,  73%] loss: 0.007\n","[epoch: 15, id:  2301,  76%] loss: 0.007\n","[epoch: 15, id:  2401,  80%] loss: 0.007\n","[epoch: 15, id:  2501,  83%] loss: 0.007\n","[epoch: 15, id:  2601,  86%] loss: 0.007\n","[epoch: 15, id:  2701,  90%] loss: 0.007\n","[epoch: 15, id:  2801,  93%] loss: 0.007\n","[epoch: 15, id:  2901,  96%] loss: 0.007\n","[epoch: 16, id:     1,   0%] loss: 0.000\n","[epoch: 16, id:   101,   3%] loss: 0.003\n","[epoch: 16, id:   201,   6%] loss: 0.003\n","[epoch: 16, id:   301,  10%] loss: 0.003\n","[epoch: 16, id:   401,  13%] loss: 0.003\n","[epoch: 16, id:   501,  16%] loss: 0.003\n","[epoch: 16, id:   601,  20%] loss: 0.003\n","[epoch: 16, id:   701,  23%] loss: 0.004\n","[epoch: 16, id:   801,  26%] loss: 0.005\n","[epoch: 16, id:   901,  30%] loss: 0.005\n","[epoch: 16, id:  1001,  33%] loss: 0.005\n","[epoch: 16, id:  1101,  36%] loss: 0.005\n","[epoch: 16, id:  1201,  40%] loss: 0.005\n","[epoch: 16, id:  1301,  43%] loss: 0.005\n","[epoch: 16, id:  1401,  46%] loss: 0.005\n","[epoch: 16, id:  1501,  50%] loss: 0.005\n","[epoch: 16, id:  1601,  53%] loss: 0.005\n","[epoch: 16, id:  1701,  56%] loss: 0.005\n","[epoch: 16, id:  1801,  60%] loss: 0.005\n","[epoch: 16, id:  1901,  63%] loss: 0.005\n","[epoch: 16, id:  2001,  66%] loss: 0.005\n","[epoch: 16, id:  2101,  70%] loss: 0.005\n","[epoch: 16, id:  2201,  73%] loss: 0.005\n","[epoch: 16, id:  2301,  76%] loss: 0.005\n","[epoch: 16, id:  2401,  80%] loss: 0.005\n","[epoch: 16, id:  2501,  83%] loss: 0.005\n","[epoch: 16, id:  2601,  86%] loss: 0.005\n","[epoch: 16, id:  2701,  90%] loss: 0.005\n","[epoch: 16, id:  2801,  93%] loss: 0.005\n","[epoch: 16, id:  2901,  96%] loss: 0.005\n","[epoch: 17, id:     1,   0%] loss: 0.000\n","[epoch: 17, id:   101,   3%] loss: 0.004\n","[epoch: 17, id:   201,   6%] loss: 0.004\n","[epoch: 17, id:   301,  10%] loss: 0.004\n","[epoch: 17, id:   401,  13%] loss: 0.004\n","[epoch: 17, id:   501,  16%] loss: 0.004\n","[epoch: 17, id:   601,  20%] loss: 0.003\n","[epoch: 17, id:   701,  23%] loss: 0.003\n","[epoch: 17, id:   801,  26%] loss: 0.003\n","[epoch: 17, id:   901,  30%] loss: 0.003\n","[epoch: 17, id:  1001,  33%] loss: 0.003\n","[epoch: 17, id:  1101,  36%] loss: 0.003\n","[epoch: 17, id:  1201,  40%] loss: 0.003\n","[epoch: 17, id:  1301,  43%] loss: 0.003\n","[epoch: 17, id:  1401,  46%] loss: 0.004\n","[epoch: 17, id:  1501,  50%] loss: 0.004\n","[epoch: 17, id:  1601,  53%] loss: 0.004\n","[epoch: 17, id:  1701,  56%] loss: 0.003\n","[epoch: 17, id:  1801,  60%] loss: 0.004\n","[epoch: 17, id:  1901,  63%] loss: 0.004\n","[epoch: 17, id:  2001,  66%] loss: 0.004\n","[epoch: 17, id:  2101,  70%] loss: 0.004\n","[epoch: 17, id:  2201,  73%] loss: 0.004\n","[epoch: 17, id:  2301,  76%] loss: 0.004\n","[epoch: 17, id:  2401,  80%] loss: 0.004\n","[epoch: 17, id:  2501,  83%] loss: 0.005\n","[epoch: 17, id:  2601,  86%] loss: 0.005\n","[epoch: 17, id:  2701,  90%] loss: 0.005\n","[epoch: 17, id:  2801,  93%] loss: 0.005\n","[epoch: 17, id:  2901,  96%] loss: 0.004\n","[epoch: 18, id:     1,   0%] loss: 0.006\n","[epoch: 18, id:   101,   3%] loss: 0.002\n","[epoch: 18, id:   201,   6%] loss: 0.002\n","[epoch: 18, id:   301,  10%] loss: 0.002\n","[epoch: 18, id:   401,  13%] loss: 0.002\n","[epoch: 18, id:   501,  16%] loss: 0.003\n","[epoch: 18, id:   601,  20%] loss: 0.003\n","[epoch: 18, id:   701,  23%] loss: 0.003\n","[epoch: 18, id:   801,  26%] loss: 0.002\n","[epoch: 18, id:   901,  30%] loss: 0.002\n","[epoch: 18, id:  1001,  33%] loss: 0.003\n","[epoch: 18, id:  1101,  36%] loss: 0.003\n","[epoch: 18, id:  1201,  40%] loss: 0.003\n","[epoch: 18, id:  1301,  43%] loss: 0.003\n","[epoch: 18, id:  1401,  46%] loss: 0.003\n","[epoch: 18, id:  1501,  50%] loss: 0.003\n","[epoch: 18, id:  1601,  53%] loss: 0.003\n","[epoch: 18, id:  1701,  56%] loss: 0.003\n","[epoch: 18, id:  1801,  60%] loss: 0.003\n","[epoch: 18, id:  1901,  63%] loss: 0.003\n","[epoch: 18, id:  2001,  66%] loss: 0.004\n","[epoch: 18, id:  2101,  70%] loss: 0.004\n","[epoch: 18, id:  2201,  73%] loss: 0.003\n","[epoch: 18, id:  2301,  76%] loss: 0.004\n","[epoch: 18, id:  2401,  80%] loss: 0.004\n","[epoch: 18, id:  2501,  83%] loss: 0.004\n","[epoch: 18, id:  2601,  86%] loss: 0.004\n","[epoch: 18, id:  2701,  90%] loss: 0.004\n","[epoch: 18, id:  2801,  93%] loss: 0.004\n","[epoch: 18, id:  2901,  96%] loss: 0.004\n","[epoch: 19, id:     1,   0%] loss: 0.003\n","[epoch: 19, id:   101,   3%] loss: 0.003\n","[epoch: 19, id:   201,   6%] loss: 0.003\n","[epoch: 19, id:   301,  10%] loss: 0.003\n","[epoch: 19, id:   401,  13%] loss: 0.003\n","[epoch: 19, id:   501,  16%] loss: 0.004\n","[epoch: 19, id:   601,  20%] loss: 0.003\n","[epoch: 19, id:   701,  23%] loss: 0.003\n","[epoch: 19, id:   801,  26%] loss: 0.003\n","[epoch: 19, id:   901,  30%] loss: 0.003\n","[epoch: 19, id:  1001,  33%] loss: 0.003\n","[epoch: 19, id:  1101,  36%] loss: 0.003\n","[epoch: 19, id:  1201,  40%] loss: 0.003\n","[epoch: 19, id:  1301,  43%] loss: 0.003\n","[epoch: 19, id:  1401,  46%] loss: 0.003\n","[epoch: 19, id:  1501,  50%] loss: 0.003\n","[epoch: 19, id:  1601,  53%] loss: 0.003\n","[epoch: 19, id:  1701,  56%] loss: 0.003\n","[epoch: 19, id:  1801,  60%] loss: 0.003\n","[epoch: 19, id:  1901,  63%] loss: 0.003\n","[epoch: 19, id:  2001,  66%] loss: 0.003\n","[epoch: 19, id:  2101,  70%] loss: 0.003\n","[epoch: 19, id:  2201,  73%] loss: 0.003\n","[epoch: 19, id:  2301,  76%] loss: 0.003\n","[epoch: 19, id:  2401,  80%] loss: 0.003\n","[epoch: 19, id:  2501,  83%] loss: 0.003\n","[epoch: 19, id:  2601,  86%] loss: 0.003\n","[epoch: 19, id:  2701,  90%] loss: 0.003\n","[epoch: 19, id:  2801,  93%] loss: 0.003\n","[epoch: 19, id:  2901,  96%] loss: 0.003\n","[epoch: 20, id:     1,   0%] loss: 0.000\n","[epoch: 20, id:   101,   3%] loss: 0.003\n","[epoch: 20, id:   201,   6%] loss: 0.004\n","[epoch: 20, id:   301,  10%] loss: 0.003\n","[epoch: 20, id:   401,  13%] loss: 0.003\n","[epoch: 20, id:   501,  16%] loss: 0.003\n","[epoch: 20, id:   601,  20%] loss: 0.003\n","[epoch: 20, id:   701,  23%] loss: 0.003\n","[epoch: 20, id:   801,  26%] loss: 0.002\n","[epoch: 20, id:   901,  30%] loss: 0.002\n","[epoch: 20, id:  1001,  33%] loss: 0.002\n","[epoch: 20, id:  1101,  36%] loss: 0.002\n","[epoch: 20, id:  1201,  40%] loss: 0.002\n","[epoch: 20, id:  1301,  43%] loss: 0.002\n","[epoch: 20, id:  1401,  46%] loss: 0.002\n","[epoch: 20, id:  1501,  50%] loss: 0.002\n","[epoch: 20, id:  1601,  53%] loss: 0.002\n","[epoch: 20, id:  1701,  56%] loss: 0.002\n","[epoch: 20, id:  1801,  60%] loss: 0.002\n","[epoch: 20, id:  1901,  63%] loss: 0.002\n","[epoch: 20, id:  2001,  66%] loss: 0.002\n","[epoch: 20, id:  2101,  70%] loss: 0.002\n","[epoch: 20, id:  2201,  73%] loss: 0.002\n","[epoch: 20, id:  2301,  76%] loss: 0.002\n","[epoch: 20, id:  2401,  80%] loss: 0.002\n","[epoch: 20, id:  2501,  83%] loss: 0.002\n","[epoch: 20, id:  2601,  86%] loss: 0.002\n","[epoch: 20, id:  2701,  90%] loss: 0.002\n","[epoch: 20, id:  2801,  93%] loss: 0.002\n","[epoch: 20, id:  2901,  96%] loss: 0.002\n"]}],"source":["for epoch in range(20):\n","    loss_sum = []\n","    metric_sum = 0.0\n","    for i, data in enumerate(trainloader):\n","        (features, labels) = data\n","        loss, metric = train_step(cnn, features=features, labels=labels)\n","        loss_sum.append(loss)\n","        metric_sum += metric\n","        loss_sum.append(loss.item())\n","        if i % 100 == 0:\n","            print('[epoch: %d, id: %5d, %3d%%] loss: %.3f' %\n","                  (epoch + 1, i + 1, 100 * i / len(trainloader), torch.mean(torch.Tensor(loss_sum))))\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"interpreter":{"hash":"ecae59e36edac920ceb43795ff371fc2cc92248ebecf572615877361fb7f6b56"},"kernelspec":{"display_name":"Python 3.7.9 64-bit ('deeplab': conda)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.9"},"orig_nbformat":4},"nbformat":4,"nbformat_minor":2}
